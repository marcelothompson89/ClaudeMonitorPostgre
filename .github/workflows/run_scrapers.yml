name: Run Scrapers Every 6 Hours

on:
  schedule:
    - cron: '0 */6 * * *'  # Ejecutar cada 6 horas
  workflow_dispatch:  # Permite ejecutar manualmente

jobs:
  run-scrapers:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout código
      uses: actions/checkout@v3
      
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        # Instalar dependencias explícitamente necesarias para GitHub Actions
        pip install dj-database-url python-dotenv
        # Instalar dependencias del proyecto
        pip install -r requirements.txt
        # Instalar Playwright
        playwright install chromium
        
    - name: Configurar variables de entorno
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        DJANGO_SECRET_KEY: ${{ secrets.DJANGO_SECRET_KEY }}
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        DB_PORT: ${{ secrets.DB_PORT }}
      run: |
        # Creamos un archivo .env para las variables de entorno
        echo "DATABASE_URL=$DATABASE_URL" > .env
        echo "SECRET_KEY=$DJANGO_SECRET_KEY" >> .env
        echo "DB_HOST=$DB_HOST" >> .env
        echo "DB_NAME=$DB_NAME" >> .env
        echo "DB_USER=$DB_USER" >> .env
        echo "DB_PASSWORD=$DB_PASSWORD" >> .env
        echo "DB_PORT=$DB_PORT" >> .env
        echo "DEBUG=False" >> .env
        
    - name: Crear archivo de configuración simplificado
      run: |
        # Creamos un archivo de configuración simplificado para GitHub Actions
        cat > github_actions_settings.py << EOF
        # Este archivo es generado automáticamente por GitHub Actions
        
        import os
        import sys
        from pathlib import Path
        
        # Cargar variables desde .env
        from dotenv import load_dotenv
        load_dotenv()
        
        # Configuración básica
        BASE_DIR = Path(__file__).resolve().parent
        SECRET_KEY = os.environ.get('SECRET_KEY', 'django-insecure-key-for-dev')
        DEBUG = False
        
        # Configuración directa de la base de datos Supabase (PostgreSQL)
        DATABASES = {
            'default': {
                'ENGINE': 'django.db.backends.postgresql',
                'NAME': os.environ.get('DB_NAME'),
                'USER': os.environ.get('DB_USER'),
                'PASSWORD': os.environ.get('DB_PASSWORD'),
                'HOST': os.environ.get('DB_HOST'),
                'PORT': os.environ.get('DB_PORT', '5432'),
                'OPTIONS': {'sslmode': 'require'},
            }
        }
        
        # Aplicaciones instaladas necesarias para los scrapers
        INSTALLED_APPS = [
            'django.contrib.admin',
            'django.contrib.auth',
            'django.contrib.contenttypes',
            'django.contrib.sessions',
            'django.contrib.messages',
            'django.contrib.staticfiles',
            'alertas',
            'scrapers',
        ]
        
        # Configuración mínima para ejecutar comandos
        MIDDLEWARE = [
            'django.middleware.security.SecurityMiddleware',
            'django.contrib.sessions.middleware.SessionMiddleware',
            'django.middleware.common.CommonMiddleware',
            'django.middleware.csrf.CsrfViewMiddleware',
            'django.contrib.auth.middleware.AuthenticationMiddleware',
            'django.contrib.messages.middleware.MessageMiddleware',
            'django.middleware.clickjacking.XFrameOptionsMiddleware',
        ]
        
        ROOT_URLCONF = 'alertas_project.urls'
        
        TEMPLATES = [
            {
                'BACKEND': 'django.template.backends.django.DjangoTemplates',
                'DIRS': [],
                'APP_DIRS': True,
                'OPTIONS': {
                    'context_processors': [
                        'django.template.context_processors.debug',
                        'django.template.context_processors.request',
                        'django.contrib.auth.context_processors.auth',
                        'django.contrib.messages.context_processors.messages',
                    ],
                },
            },
        ]
        
        WSGI_APPLICATION = 'alertas_project.wsgi.application'
        STATIC_URL = '/static/'
        DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'
        
        ALLOWED_HOSTS = ['*']
        EOF
        
    - name: Ejecutar scrapers
      env:
        DJANGO_SETTINGS_MODULE: github_actions_settings
        PYTHONPATH: ${{ github.workspace }}
      run: |
        # Probar la conexión a la base de datos
        python -c "import django; django.setup(); from django.db import connection; cursor = connection.cursor(); cursor.execute('SELECT 1'); print('Conexión a la base de datos exitosa')"
        
        # Ejecutar todos los scrapers y guardar los resultados en formato JSON
        python manage.py run_scrapers --json > scraper_log.json
        
    - name: Guardar log de ejecución como artefacto
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: scraper_log.json
        retention-days: 5
        
    - name: Limpiar archivos temporales
      if: always()
      run: |
        rm -f .env github_actions_settings.py